{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87aa18af-3840-4018-a788-c6d193799b54",
      "metadata": {
        "id": "87aa18af-3840-4018-a788-c6d193799b54"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentencepiece datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8erPdx2JgYAS",
      "metadata": {
        "id": "8erPdx2JgYAS"
      },
      "outputs": [],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ek_OlvEqlfwM",
      "metadata": {
        "id": "ek_OlvEqlfwM"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uG2dj2JZTLuf",
      "metadata": {
        "id": "uG2dj2JZTLuf"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S_odkf81S2dB",
      "metadata": {
        "id": "S_odkf81S2dB"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "#bigscience/bloomz-560m\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdda9392-0bfd-419d-bd3c-3b305fd6fa35",
      "metadata": {
        "id": "fdda9392-0bfd-419d-bd3c-3b305fd6fa35"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"glue\", \"sst2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952b9693-f642-4cdc-b904-071358342310",
      "metadata": {
        "id": "952b9693-f642-4cdc-b904-071358342310",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26da3d5d-52e4-4b19-965d-3abf49ddb02b",
      "metadata": {
        "id": "26da3d5d-52e4-4b19-965d-3abf49ddb02b"
      },
      "outputs": [],
      "source": [
        "\n",
        "#from bertlt import  PrefixForSequenceClassification, PromptForSequenceClassification\n",
        "from transformers import AutoConfig\n",
        "config = AutoConfig.from_pretrained(\"Kowsher/L-Tuning\")\n",
        "config._name_or_path=model_name\n",
        "config.hidden_size=768\n",
        "config.num_hidden_layers=12\n",
        "config.n_head=12\n",
        "config.num_labels=2\n",
        "config.pad_token_id=tokenizer.pad_token_id\n",
        "config.hidden_dropout = 0.01\n",
        "config.model_type='bert'\n",
        "config.cls_token_id=tokenizer.cls_token_id\n",
        "config.sep_token_id=tokenizer.sep_token_id\n",
        "config.pooling=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe567bc-af62-4750-b6a4-40b33e766842",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fe567bc-af62-4750-b6a4-40b33e766842",
        "outputId": "4ea7ea2b-2357-473d-e18c-4efcd4a05985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prefix c (pre_seq_len) is 10\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "import torch\n",
        "import random\n",
        "from DataCollator import DataCollatorForLTCls\n",
        "# define the label correctly from the dataset\n",
        "label2prompt = {0: 'The text has negative sentiment, text: ',  1: 'The text has positive sentiment, text: '}\n",
        "\n",
        "data_collator = DataCollatorForLTCls(config, tokenizer, label2prompt)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80565bcb-1547-4eb9-84ee-e914f98adf72",
      "metadata": {
        "id": "80565bcb-1547-4eb9-84ee-e914f98adf72"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa388ef6-4f85-4094-8675-1321ac3faf18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa388ef6-4f85-4094-8675-1321ac3faf18",
        "outputId": "ddae6d55-1b39-4e6d-8ed5-223e7a6d5fd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of PrefixForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'prefix_encoder.projection.bias', 'prefix_encoder.W.bias', 'classifier.bias', 'prefix_encoder.W.weight', 'prefix_encoder.projection.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from bertlt import PrefixForSequenceClassification\n",
        "config.pre_seq_len=10\n",
        "\n",
        "model = PrefixForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1429167a-3b74-4686-bccc-ea7804e6cad0",
      "metadata": {
        "id": "1429167a-3b74-4686-bccc-ea7804e6cad0",
        "outputId": "3706ae68-6269-4968-e072-b24c3a585591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Parameters: 111512067\n",
            "Trainable Parameters: 2029827\n",
            "Percentage Trainable: 1.82027564783639084212%\n"
          ]
        }
      ],
      "source": [
        "# Total number of parameters in the model\n",
        "total_parameters = model.num_parameters()\n",
        "\n",
        "# Total number of trainable parameters in the model\n",
        "trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Calculate the percentage of trainable parameters\n",
        "percentage_trainable = (trainable_parameters / total_parameters) * 100\n",
        "\n",
        "print(f\"Total Parameters: {total_parameters}\")\n",
        "print(f\"Trainable Parameters: {trainable_parameters}\")\n",
        "print(f\"Percentage Trainable: {percentage_trainable:.20f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680aa280-2e2f-410a-882b-cb016e938368",
      "metadata": {
        "id": "680aa280-2e2f-410a-882b-cb016e938368"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d912acf-1b7d-4bb2-9bd6-977639168580",
      "metadata": {
        "id": "3d912acf-1b7d-4bb2-9bd6-977639168580",
        "outputId": "76ba2a8e-606f-4d81-ff11-9cb19695ee44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/kowsher/miniconda3/envs/LT did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('@/tmp/.ICE-unix/1423,unix/kowsher-XPS-8950'), PosixPath('local/kowsher-XPS-8950')}\n",
            "  warn(msg)\n",
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/etc/xdg/xdg-ubuntu')}\n",
            "  warn(msg)\n",
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('0'), PosixPath('1')}\n",
            "  warn(msg)\n",
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/org/gnome/Terminal/screen/d5ea2a9b_bcca_41aa_bc1c_68630b6c7485')}\n",
            "  warn(msg)\n",
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
            "  warn(msg)\n",
            "/home/kowsher/miniconda3/envs/LT/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
        "from sklearn.metrics import r2_score, accuracy_score, matthews_corrcoef\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    logits = p.predictions\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "\n",
        "\n",
        "    return {\"acc\": accuracy}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./rfalcon_task1',\n",
        "    num_train_epochs=10,\n",
        "    do_eval=True,\n",
        "    #learning_rate=0.001,\n",
        "    #bf16=True,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "\n",
        "    logging_dir='./logs',\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps = 100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    #optim=\"paged_adamw_8bit\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d6a7bf2-41e2-4be0-beaf-07a7d1f48112",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "5d6a7bf2-41e2-4be0-beaf-07a7d1f48112",
        "outputId": "13205143-d5d3-4bea-e8af-973bb1da2c2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11800' max='21050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11800/21050 41:15 < 32:20, 4.77 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.700800</td>\n",
              "      <td>0.694393</td>\n",
              "      <td>0.530963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.694900</td>\n",
              "      <td>0.693684</td>\n",
              "      <td>0.532110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.692300</td>\n",
              "      <td>0.692712</td>\n",
              "      <td>0.520642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.692900</td>\n",
              "      <td>0.692547</td>\n",
              "      <td>0.525229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.690300</td>\n",
              "      <td>0.691718</td>\n",
              "      <td>0.487385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.687700</td>\n",
              "      <td>0.691729</td>\n",
              "      <td>0.488532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.688800</td>\n",
              "      <td>0.691727</td>\n",
              "      <td>0.517202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.680900</td>\n",
              "      <td>0.694681</td>\n",
              "      <td>0.516055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.678300</td>\n",
              "      <td>0.693540</td>\n",
              "      <td>0.508028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.676100</td>\n",
              "      <td>0.692038</td>\n",
              "      <td>0.512615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.677000</td>\n",
              "      <td>0.688766</td>\n",
              "      <td>0.518349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.674600</td>\n",
              "      <td>0.678537</td>\n",
              "      <td>0.550459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.659800</td>\n",
              "      <td>0.671126</td>\n",
              "      <td>0.566514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.665400</td>\n",
              "      <td>0.654939</td>\n",
              "      <td>0.595183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.653900</td>\n",
              "      <td>0.633424</td>\n",
              "      <td>0.635321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.652100</td>\n",
              "      <td>0.615665</td>\n",
              "      <td>0.659404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.631900</td>\n",
              "      <td>0.589478</td>\n",
              "      <td>0.682339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.600700</td>\n",
              "      <td>0.553182</td>\n",
              "      <td>0.715596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.565600</td>\n",
              "      <td>0.492982</td>\n",
              "      <td>0.753440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.526500</td>\n",
              "      <td>0.493099</td>\n",
              "      <td>0.740826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.537400</td>\n",
              "      <td>0.451322</td>\n",
              "      <td>0.793578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.491900</td>\n",
              "      <td>0.428638</td>\n",
              "      <td>0.808486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.450200</td>\n",
              "      <td>0.408284</td>\n",
              "      <td>0.795872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.437200</td>\n",
              "      <td>0.363269</td>\n",
              "      <td>0.842890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.402900</td>\n",
              "      <td>0.332057</td>\n",
              "      <td>0.865826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.362400</td>\n",
              "      <td>0.322512</td>\n",
              "      <td>0.871560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.353500</td>\n",
              "      <td>0.316138</td>\n",
              "      <td>0.866972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.327300</td>\n",
              "      <td>0.314573</td>\n",
              "      <td>0.865826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.332100</td>\n",
              "      <td>0.312762</td>\n",
              "      <td>0.866972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.328500</td>\n",
              "      <td>0.311945</td>\n",
              "      <td>0.872706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.329300</td>\n",
              "      <td>0.308776</td>\n",
              "      <td>0.870413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>0.314003</td>\n",
              "      <td>0.865826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.326600</td>\n",
              "      <td>0.304970</td>\n",
              "      <td>0.868119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.315800</td>\n",
              "      <td>0.307564</td>\n",
              "      <td>0.866972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.325400</td>\n",
              "      <td>0.300532</td>\n",
              "      <td>0.876147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.303800</td>\n",
              "      <td>0.305623</td>\n",
              "      <td>0.873853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.299700</td>\n",
              "      <td>0.310850</td>\n",
              "      <td>0.870413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.311000</td>\n",
              "      <td>0.299291</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.316400</td>\n",
              "      <td>0.294666</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.307300</td>\n",
              "      <td>0.304989</td>\n",
              "      <td>0.870413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.309200</td>\n",
              "      <td>0.306408</td>\n",
              "      <td>0.872706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>0.294622</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.299400</td>\n",
              "      <td>0.290776</td>\n",
              "      <td>0.878440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.286100</td>\n",
              "      <td>0.291251</td>\n",
              "      <td>0.876147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.306000</td>\n",
              "      <td>0.284665</td>\n",
              "      <td>0.873853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.286400</td>\n",
              "      <td>0.291988</td>\n",
              "      <td>0.876147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.315300</td>\n",
              "      <td>0.283718</td>\n",
              "      <td>0.873853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.289100</td>\n",
              "      <td>0.279321</td>\n",
              "      <td>0.879587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.295800</td>\n",
              "      <td>0.281466</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.296600</td>\n",
              "      <td>0.286088</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.290300</td>\n",
              "      <td>0.284724</td>\n",
              "      <td>0.883028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.272000</td>\n",
              "      <td>0.283799</td>\n",
              "      <td>0.879587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.289600</td>\n",
              "      <td>0.279769</td>\n",
              "      <td>0.881881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.277600</td>\n",
              "      <td>0.281663</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.283600</td>\n",
              "      <td>0.281042</td>\n",
              "      <td>0.883028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.276400</td>\n",
              "      <td>0.288727</td>\n",
              "      <td>0.879587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.273800</td>\n",
              "      <td>0.283781</td>\n",
              "      <td>0.879587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.288900</td>\n",
              "      <td>0.280440</td>\n",
              "      <td>0.881881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.273000</td>\n",
              "      <td>0.283327</td>\n",
              "      <td>0.879587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.277300</td>\n",
              "      <td>0.286587</td>\n",
              "      <td>0.881881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.253600</td>\n",
              "      <td>0.283280</td>\n",
              "      <td>0.879587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.298400</td>\n",
              "      <td>0.275389</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.293300</td>\n",
              "      <td>0.273465</td>\n",
              "      <td>0.885321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.268200</td>\n",
              "      <td>0.277512</td>\n",
              "      <td>0.883028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.298100</td>\n",
              "      <td>0.277197</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.270100</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.885321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.279200</td>\n",
              "      <td>0.283932</td>\n",
              "      <td>0.881881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.255900</td>\n",
              "      <td>0.277046</td>\n",
              "      <td>0.883028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.288800</td>\n",
              "      <td>0.270751</td>\n",
              "      <td>0.884174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.286500</td>\n",
              "      <td>0.270244</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.273800</td>\n",
              "      <td>0.269640</td>\n",
              "      <td>0.888761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.266400</td>\n",
              "      <td>0.269229</td>\n",
              "      <td>0.892202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.281600</td>\n",
              "      <td>0.269479</td>\n",
              "      <td>0.883028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.275400</td>\n",
              "      <td>0.264104</td>\n",
              "      <td>0.891055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.272200</td>\n",
              "      <td>0.275724</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.271300</td>\n",
              "      <td>0.266107</td>\n",
              "      <td>0.894495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.267900</td>\n",
              "      <td>0.267270</td>\n",
              "      <td>0.881881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.251900</td>\n",
              "      <td>0.268715</td>\n",
              "      <td>0.895642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.276400</td>\n",
              "      <td>0.273109</td>\n",
              "      <td>0.877294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.260200</td>\n",
              "      <td>0.269612</td>\n",
              "      <td>0.886468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.258600</td>\n",
              "      <td>0.267052</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.274900</td>\n",
              "      <td>0.269596</td>\n",
              "      <td>0.883028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.272400</td>\n",
              "      <td>0.262758</td>\n",
              "      <td>0.888761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.257800</td>\n",
              "      <td>0.264836</td>\n",
              "      <td>0.885321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>0.265897</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.257000</td>\n",
              "      <td>0.266097</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.267300</td>\n",
              "      <td>0.263622</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.266100</td>\n",
              "      <td>0.267725</td>\n",
              "      <td>0.886468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.257200</td>\n",
              "      <td>0.266481</td>\n",
              "      <td>0.881881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.265305</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.266900</td>\n",
              "      <td>0.262102</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.260754</td>\n",
              "      <td>0.894495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.265100</td>\n",
              "      <td>0.268091</td>\n",
              "      <td>0.884174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.255300</td>\n",
              "      <td>0.267758</td>\n",
              "      <td>0.886468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.265000</td>\n",
              "      <td>0.265933</td>\n",
              "      <td>0.886468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.245700</td>\n",
              "      <td>0.264337</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.258800</td>\n",
              "      <td>0.262587</td>\n",
              "      <td>0.889908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.265600</td>\n",
              "      <td>0.255156</td>\n",
              "      <td>0.894495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.263600</td>\n",
              "      <td>0.256928</td>\n",
              "      <td>0.893349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.237200</td>\n",
              "      <td>0.269064</td>\n",
              "      <td>0.888761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.238300</td>\n",
              "      <td>0.264008</td>\n",
              "      <td>0.891055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.257300</td>\n",
              "      <td>0.259304</td>\n",
              "      <td>0.894495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.265146</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.257100</td>\n",
              "      <td>0.264163</td>\n",
              "      <td>0.896789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.244400</td>\n",
              "      <td>0.273051</td>\n",
              "      <td>0.891055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.263000</td>\n",
              "      <td>0.262443</td>\n",
              "      <td>0.891055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.257700</td>\n",
              "      <td>0.260273</td>\n",
              "      <td>0.892202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.242600</td>\n",
              "      <td>0.263960</td>\n",
              "      <td>0.892202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.256000</td>\n",
              "      <td>0.256511</td>\n",
              "      <td>0.892202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.251200</td>\n",
              "      <td>0.265370</td>\n",
              "      <td>0.892202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.257800</td>\n",
              "      <td>0.274521</td>\n",
              "      <td>0.893349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.245600</td>\n",
              "      <td>0.267477</td>\n",
              "      <td>0.895642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11300</td>\n",
              "      <td>0.263800</td>\n",
              "      <td>0.268366</td>\n",
              "      <td>0.896789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.278800</td>\n",
              "      <td>0.276566</td>\n",
              "      <td>0.896789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.264800</td>\n",
              "      <td>0.267752</td>\n",
              "      <td>0.895642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.257700</td>\n",
              "      <td>0.259956</td>\n",
              "      <td>0.903349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11700</td>\n",
              "      <td>0.246300</td>\n",
              "      <td>0.264840</td>\n",
              "      <td>0.924495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.238700</td>\n",
              "      <td>0.263814</td>\n",
              "      <td>0.930349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11800, training_loss=0.3509729212421482, metrics={'train_runtime': 2475.4853, 'train_samples_per_second': 272.064, 'train_steps_per_second': 8.503, 'total_flos': 2.542217749352064e+16, 'train_loss': 0.3509729212421482, 'epoch': 5.61})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    compute_metrics=compute_metrics, #compute_metrics1,#compute_metrics_classification,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=20)]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0244830-9fd3-483c-b464-0092a13522b3",
      "metadata": {
        "id": "b0244830-9fd3-483c-b464-0092a13522b3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
